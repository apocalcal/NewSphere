"""
íŒŒì¼ì„œë²„ ê¸°ë°˜ ë°ì´í„° ì €ì¥/ì¡°íšŒ ì„œë¹„ìŠ¤
Redisë¥¼ ëŒ€ì²´í•˜ì—¬ CSV íŒŒì¼ í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ê´€ë¦¬
"""

import os
import csv
import json
import glob
import requests
from datetime import datetime
from typing import List, Optional, Dict, Any
from pathlib import Path
from io import StringIO
import structlog

from app.models.schemas import NewsDetail, RelatedNewsPair
from app.config import settings

logger = structlog.get_logger()

class FileServerService:
    """
    íŒŒì¼ì„œë²„ ê´€ë¦¬ ì„œë¹„ìŠ¤ - íŒŒì¼ ê¸°ë°˜ ì¤‘ê°„ ì €ì¥ì†Œ
    
    ì—­í• :
    - ë‰´ìŠ¤ ë°ì´í„°ë¥¼ íŒŒì¼ì‹œìŠ¤í…œì— CSV í˜•íƒœë¡œ ì €ì¥/ì¡°íšŒ
    - Java-Python ì„œë¹„ìŠ¤ ê°„ ë°ì´í„° êµí™˜ ë§¤ê°œì²´
    - ì‹œê°„ ê¸°ë°˜ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ê´€ë¦¬
    
    ê¸°ëŠ¥:
    - CSV ì €ì¥: ë‰´ìŠ¤ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ CSV íŒŒì¼ë¡œ ì €ì¥
    - CSV ì¡°íšŒ: ì €ì¥ëœ CSV íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ê°ì²´ë¡œ ë³€í™˜
    - ìµœì‹  íŒŒì¼ íƒìƒ‰: íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ìµœì‹  ë°ì´í„° ìë™ ê°ì§€
    - ë””ë ‰í„°ë¦¬ ê´€ë¦¬: am/pm ê¸°ë°˜ ì‹œê°„ëŒ€ë³„ í´ë” êµ¬ì¡° ìƒì„±
    
    íŒŒì¼ êµ¬ì¡°:
    - ê²½ë¡œ: {base_path}/{am|pm}/{yyyy-MM-dd}_{am|pm}/{stage}/
    - íŒŒì¼ëª…: {category}_{stage}_{yyyy-MM-dd-HH-mm}.csv
    - ë‹¨ê³„: list â†’ detail â†’ deduplicated â†’ related
    """
    
    def __init__(self):
        self.base_path = getattr(settings, 'FILESERVER_PATH', '/data/news-fileserver')
        self.time_format = "%Y-%m-%d"
        self.hour_format = "%H"
        
    def _get_current_time_path(self) -> str:
        """
        í˜„ì¬ ì‹œê°„ ê¸°ë°˜ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ìƒì„±
        ì˜ˆ: /data/news-fileserver/am/2025-08-19_am/ ë˜ëŠ” /data/news-fileserver/pm/2025-08-19_pm/
        """
        now = datetime.now()
        date_str = now.strftime(self.time_format)
        period = "am" if now.hour < 12 else "pm"
        return f"{self.base_path}/{period}/{date_str}_{period}"
    
    def _find_latest_file(self, dir_path: str, file_pattern: str) -> Optional[str]:
        """
        ë””ë ‰í„°ë¦¬ì—ì„œ íŒ¨í„´ì— ë§ëŠ” ìµœì‹  íŒŒì¼ ì°¾ê¸°
        
        Args:
            dir_path: ê²€ìƒ‰í•  ë””ë ‰í„°ë¦¬ ê²½ë¡œ
            file_pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: politics_detail_*.csv)
            
        Returns:
            ìµœì‹  íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ ë˜ëŠ” None
        """
        try:
            # HTTP íŒŒì¼ì„œë²„ì—ì„œ ìµœì‹  íŒŒì¼ ì°¾ê¸°
            return self._find_latest_file_from_server(dir_path, file_pattern)
            
        except Exception as e:
            logger.error(f"ğŸ“ ìµœì‹  íŒŒì¼ ê²€ìƒ‰ ì‹¤íŒ¨: {dir_path}/{file_pattern}, ì˜¤ë¥˜: {e}")
            return None
    
    def _find_latest_file_from_server(self, dir_path: str, file_pattern: str) -> Optional[str]:
        """
        HTTP íŒŒì¼ì„œë²„ì—ì„œ ìµœì‹  íŒŒì¼ ì°¾ê¸°
        """
        try:
            # í˜„ì¬ ì‹œê°„ë¶€í„° 10ë¶„ ì „ê¹Œì§€ ì‹œë„
            from datetime import datetime, timedelta
            
            base_pattern = file_pattern.replace("*", "")  # politics_detail_.csv
            category_stage = base_pattern.replace(".csv", "")  # politics_detail_
            
            for i in range(30):  # ìµœëŒ€ 10ë¶„ ì „ê¹Œì§€
                try_time = datetime.now() - timedelta(minutes=i)
                timestamp = try_time.strftime("%Y-%m-%d-%H-%M")
                filename = f"{category_stage}{timestamp}.csv"
                full_url = f"{dir_path}/{filename}"
                
                # HTTP GETìœ¼ë¡œ íŒŒì¼ ì¡´ì¬ í™•ì¸
                try:
                    response = requests.get(full_url, timeout=5)
                    if response.status_code == 200:
                        logger.info(f"ğŸ“ ìµœì‹  íŒŒì¼ ë°œê²¬: {full_url}")
                        return full_url
                except requests.RequestException:
                    continue
                    
            return None
            
        except Exception as e:
            logger.error(f"ğŸ“ HTTP íŒŒì¼ì„œë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def _download_file_from_server(self, file_url: str) -> Optional[str]:
        """
        HTTP íŒŒì¼ì„œë²„ì—ì„œ íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
        
        Args:
            file_url: íŒŒì¼ì˜ HTTP URL
            
        Returns:
            íŒŒì¼ ë‚´ìš© ë¬¸ìì—´ ë˜ëŠ” None
        """
        try:
            response = requests.get(file_url, timeout=10)
            if response.status_code == 200:
                logger.info(f"ğŸ“ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {file_url}")
                return response.text
            else:
                logger.warning(f"ğŸ“ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {file_url} - ìƒíƒœì½”ë“œ: {response.status_code}")
                return None
                
        except requests.RequestException as e:
            logger.error(f"ğŸ“ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {file_url}, ì˜¤ë¥˜: {e}")
            return None
    
    def _ensure_directory(self, dir_path: str):
        """ë””ë ‰í„°ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def _upload_file_to_server(self, upload_url: str, content: str):
        """Java í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ì˜ FTP APIë¥¼ í†µí•´ íŒŒì¼ ì—…ë¡œë“œ"""
        try:
            # upload_urlì—ì„œ ê²½ë¡œì™€ íŒŒì¼ëª… ì¶”ì¶œ
            # ì˜ˆ: "http://dev.macacolabs.site:8008/1/pm/2025-08-19_pm/deduplicated/politics_deduplicated_2025-08-19-17-45.csv"
            # â†’ path: "pm/2025-08-19_pm/deduplicated/", filename: "politics_deduplicated_2025-08-19-17-45.csv"
            
            url_parts = upload_url.replace("http://dev.macacolabs.site:8008/1/", "")
            path_parts = url_parts.split("/")
            filename = path_parts[-1]
            relative_path = "/".join(path_parts[:-1]) + "/"
            
            # Java í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ì˜ FTP API í˜¸ì¶œ
            ftp_api_url = "http://localhost:8083/api/ftp/upload"
            
            payload = {
                "path": relative_path,
                "filename": filename,
                "content": content
            }
            
            headers = {
                'Content-Type': 'application/json; charset=utf-8',
                'Accept-Charset': 'UTF-8'
            }
            
            response = requests.post(ftp_api_url, json=payload, headers=headers)
            response.raise_for_status()
            
            logger.debug(f"FTP API ì—…ë¡œë“œ ì„±ê³µ: {relative_path}{filename}")
            
        except Exception as e:
            logger.error(f"FTP API ì—…ë¡œë“œ ì˜¤ë¥˜: {upload_url}, ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"FTP API ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_news_to_csv(self, category: str, news_list: List[NewsDetail], stage: str) -> str:
        """
        ë‰´ìŠ¤ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ (POLITICS, ECONOMY ë“±)
            news_list: ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            stage: ë‹¨ê³„ (list, detail, deduplicated)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            time_path = self._get_current_time_path()
            dir_path = f"{time_path}/{stage}"
            
            timestamp = datetime.now().strftime("%Y-%m-%d-%H-%M")
            file_name = f"{category.lower()}_{stage}_{timestamp}.csv"
            
            # CSV ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ìƒì„±
            csv_content = StringIO()
            fieldnames = [
                'title', 'press', 'reporter', 'date', 'link',
                'imageUrl', 'oidAid', 'trusted', 'content', 'dedupState',
                'categoryName', 'createdAt'
            ]
            writer = csv.DictWriter(csv_content, fieldnames=fieldnames)
            
            # í—¤ë” ì“°ê¸°
            writer.writeheader()
            
            # ë°ì´í„° ì“°ê¸°
            for news in news_list:
                row = {
                    'title': news.title or '',
                    'press': news.press or '',
                    'reporter': news.reporter or '',
                    'date': news.date or '',
                    'link': news.link or '',
                    'imageUrl': news.image_url or '',
                    'oidAid': news.oid_aid or '',
                    'trusted': news.trusted or 0,
                    'content': news.content or '',
                    'dedupState': news.dedup_state or '',
                    'categoryName': news.category_name or category,  # ì¹´í…Œê³ ë¦¬ëª… ë³´ì¡´
                    'createdAt': news.created_at or datetime.now().isoformat()  # ìƒì„±ì‹œê°„ ë³´ì¡´
                }
                writer.writerow(row)
            
            # HTTP íŒŒì¼ì„œë²„ì— ì—…ë¡œë“œ
            upload_url = f"{dir_path}/{file_name}"
            self._upload_file_to_server(upload_url, csv_content.getvalue())
            
            logger.info(f"ğŸ“ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì™„ë£Œ: {upload_url} - ì¹´í…Œê³ ë¦¬: {category}, ê°œìˆ˜: {len(news_list)}")
            return upload_url
            
        except Exception as e:
            logger.error(f"ğŸ“ íŒŒì¼ì„œë²„ ì €ì¥ ì‹¤íŒ¨: {category}/{stage}, ì˜¤ë¥˜: {e}")
            raise
    
    def get_news_from_csv(self, category: str, stage: str, time_path: Optional[str] = None) -> List[NewsDetail]:
        """
        CSV íŒŒì¼ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        
        Args:
            category: ì¹´í…Œê³ ë¦¬
            stage: ë‹¨ê³„
            time_path: íŠ¹ì • ì‹œê°„ ê²½ë¡œ (Noneì´ë©´ ìµœì‹  ì‚¬ìš©)
            
        Returns:
            ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            if time_path is None:
                time_path = self._get_latest_time_path()
            
            dir_path = f"{time_path}/{stage}"
            
            # ìµœì‹  íŒŒì¼ ì°¾ê¸° (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
            file_pattern = f"{category.lower()}_{stage}_*.csv"
            file_path = self._find_latest_file(dir_path, file_pattern)
            
            if not file_path:
                logger.info(f"ğŸ“ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {dir_path}/{file_pattern}")
                return []
            
            news_list = []
            
            # HTTP URLì—ì„œ íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
            csv_content = self._download_file_from_server(file_path)
            if not csv_content:
                logger.error(f"ğŸ“ íŒŒì¼ì„œë²„ ì¡°íšŒ ì‹¤íŒ¨: {category}/{stage}, íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                return []
            
            # CSV ë‚´ìš©ì„ StringIOë¡œ íŒŒì‹±
            csv_reader = csv.DictReader(StringIO(csv_content))
            for row in csv_reader:
                    # trusted í•„ë“œ ì•ˆì „í•œ ë³€í™˜
                    trusted_value = row.get('trusted', '0')
                    if trusted_value in ['null', 'None', '', None]:
                        trusted_value = 0
                    else:
                        try:
                            trusted_value = int(trusted_value)
                        except (ValueError, TypeError):
                            trusted_value = 0
                    
                    news = NewsDetail(
                        title=row.get('title', ''),
                        press=row.get('press', ''),
                        reporter=row.get('reporter', ''),
                        date=row.get('date', ''),
                        link=row.get('link', ''),
                        image_url=row.get('imageUrl', ''),
                        oid_aid=row.get('oidAid', ''),
                        trusted=trusted_value,
                        content=row.get('content', ''),
                        dedup_state=row.get('dedupState', ''),
                        # CSVì—ì„œ ì¹´í…Œê³ ë¦¬ëª… ì½ê¸°
                        category_name=row.get('categoryName', category),
                        created_at=row.get('createdAt', '')
                    )
                    news_list.append(news)
            
            logger.info(f"ğŸ“ íŒŒì¼ì„œë²„ ì¡°íšŒ ì™„ë£Œ: {file_path} - ì¹´í…Œê³ ë¦¬: {category}, ê°œìˆ˜: {len(news_list)}")
            return news_list
            
        except Exception as e:
            logger.error(f"ğŸ“ íŒŒì¼ì„œë²„ ì¡°íšŒ ì‹¤íŒ¨: {category}/{stage}, ì˜¤ë¥˜: {e}")
            return []
    
    def save_related_news_to_csv(self, category: str, related_pairs: List[RelatedNewsPair]) -> str:
        """
        ì—°ê´€ë‰´ìŠ¤ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        """
        try:
            time_path = self._get_current_time_path()
            dir_path = f"{time_path}/related"
            
            timestamp = datetime.now().strftime("%Y-%m-%d-%H-%M")
            file_name = f"{category.lower()}_related_{timestamp}.csv"
            
            # CSV ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ìƒì„±
            csv_content = StringIO()
            fieldnames = ['repOidAid', 'relatedOidAid', 'similarity', 'category', 'createdAt']
            writer = csv.DictWriter(csv_content, fieldnames=fieldnames)
            
            writer.writeheader()
            for pair in related_pairs:
                row = {
                    'repOidAid': pair.rep_oid_aid,
                    'relatedOidAid': pair.related_oid_aid,
                    'similarity': pair.similarity,
                    'category': category,
                    'createdAt': datetime.now().isoformat()
                }
                writer.writerow(row)
            
            # HTTP íŒŒì¼ì„œë²„ì— ì—…ë¡œë“œ
            upload_url = f"{dir_path}/{file_name}"
            self._upload_file_to_server(upload_url, csv_content.getvalue())
            
            logger.info(f"ğŸ“ ì—°ê´€ë‰´ìŠ¤ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì™„ë£Œ: {upload_url} - ì¹´í…Œê³ ë¦¬: {category}, ê°œìˆ˜: {len(related_pairs)}")
            return upload_url
            
        except Exception as e:
            logger.error(f"ğŸ“ ì—°ê´€ë‰´ìŠ¤ íŒŒì¼ì„œë²„ ì €ì¥ ì‹¤íŒ¨: {category}, ì˜¤ë¥˜: {e}")
            raise
    
    def get_related_news_from_csv(self, category: str, time_path: Optional[str] = None) -> List[RelatedNewsPair]:
        """
        CSV íŒŒì¼ì—ì„œ ì—°ê´€ë‰´ìŠ¤ ì¡°íšŒ
        """
        try:
            if time_path is None:
                time_path = self._get_latest_time_path()
            
            dir_path = f"{time_path}/related"
            file_name = f"{category.lower()}_related_ë‚ ì§œ ë° ì‹œê°„.csv"
            file_path = f"{dir_path}/{file_name}"
            
            if not os.path.exists(file_path):
                logger.info(f"ğŸ“ ì—°ê´€ë‰´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                return []
            
            related_list = []
            with open(file_path, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    pair = RelatedNewsPair(
                        rep_oid_aid=row.get('repOidAid', ''),
                        related_oid_aid=row.get('relatedOidAid', ''),
                        similarity=float(row.get('similarity', 0.0)),
                        category=row.get('category', ''),
                        created_at=row.get('createdAt', '')
                    )
                    related_list.append(pair)
            
            logger.info(f"ğŸ“ ì—°ê´€ë‰´ìŠ¤ íŒŒì¼ì„œë²„ ì¡°íšŒ ì™„ë£Œ: {file_path} - ì¹´í…Œê³ ë¦¬: {category}, ê°œìˆ˜: {len(related_list)}")
            return related_list
            
        except Exception as e:
            logger.error(f"ğŸ“ ì—°ê´€ë‰´ìŠ¤ íŒŒì¼ì„œë²„ ì¡°íšŒ ì‹¤íŒ¨: {category}, ì˜¤ë¥˜: {e}")
            return []
    
    def _get_latest_time_path(self) -> str:
        """
        ê°€ì¥ ìµœì‹  ì‹œê°„ëŒ€ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ì°¾ê¸°
        """
        try:
            latest_path = None
            latest_time = None
            
            # am, pm ë””ë ‰í„°ë¦¬ ìˆœíšŒ
            for period in ['am', 'pm']:
                period_path = f"{self.base_path}/{period}"
                if not os.path.exists(period_path):
                    continue
                
                # í•´ë‹¹ periodì˜ ëª¨ë“  ë‚ ì§œ ë””ë ‰í„°ë¦¬ ì°¾ê¸°
                pattern = f"{period_path}/*_{period}"
                for dir_path in glob.glob(pattern):
                    try:
                        dir_name = os.path.basename(dir_path)
                        # 2025-08-19_am í˜•íƒœì—ì„œ ì‹œê°„ ì¶”ì¶œ
                        date_str = dir_name.replace(f'_{period}', '')
                        hour = 6 if period == 'am' else 18
                        dir_time = datetime.strptime(f"{date_str} {hour:02d}:00:00", "%Y-%m-%d %H:%M:%S")
                        
                        if latest_time is None or dir_time > latest_time:
                            latest_time = dir_time
                            latest_path = dir_path
                    except Exception:
                        continue
            
            if latest_path:
                logger.info(f"ğŸ“ ìµœì‹  ì‹œê°„ëŒ€ ê²½ë¡œ: {latest_path}")
                return latest_path
            else:
                # ìµœì‹  ê²½ë¡œê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ê²½ë¡œ ë°˜í™˜
                current_path = self._get_current_time_path()
                logger.info(f"ğŸ“ ìµœì‹  ê²½ë¡œ ì—†ìŒ, í˜„ì¬ ì‹œê°„ ê²½ë¡œ ì‚¬ìš©: {current_path}")
                return current_path
                
        except Exception as e:
            logger.error(f"ğŸ“ ìµœì‹  ì‹œê°„ëŒ€ ê²½ë¡œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self._get_current_time_path()
    
    def get_all_categories_latest_data(self, stage: str) -> Dict[str, List[NewsDetail]]:
        """
        ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë°ì´í„° ì¡°íšŒ
        """
        categories = ["POLITICS", "ECONOMY", "SOCIETY", "LIFE", "INTERNATIONAL", "IT_SCIENCE", "VEHICLE", "TRAVEL_FOOD", "ART"]
        latest_time_path = self._get_latest_time_path()
        
        result = {}
        for category in categories:
            news_list = self.get_news_from_csv(category, stage, latest_time_path)
            if news_list:
                result[category] = news_list
        
        return result
